{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This report was prepared with the assistance of AI"
      ],
      "metadata": {
        "id": "aa4DIdPAN93I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "XJezBMqSb8v4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Oevul6NNHCYo",
        "outputId": "2203dbbd-74dd-470a-e1a9-eb63699b0f63"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27cd7faa-aed9-49a7-b522-58acf806a292\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27cd7faa-aed9-49a7-b522-58acf806a292\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hep_img_large_gt.csv to hep_img_large_gt.csv\n",
            "Saving hep2img_large.zip to hep2img_large.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps 2,3,4"
      ],
      "metadata": {
        "id": "uFwsBa2kb-ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from skimage.measure import regionprops\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "zip_file = '/content/hep2img_large.zip'\n",
        "extract_folder = '/content/extracted_images2/hep2imglarge/hep2img_large/hep2img_large'\n",
        "\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(\"Extraction completed!\")\n",
        "\n",
        "csv_path = '/content/hep_img_large_gt.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/hep_img_large_gt.csv')\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Extract image IDs and class labels\n",
        "case_numbers = df['file']\n",
        "class_labels = df['class']\n",
        "\n",
        "# Create empty lists\n",
        "images = []\n",
        "masks = []\n",
        "\n",
        "# Load images and masks from the extracted folder\n",
        "for id in case_numbers:\n",
        "    id_str = str(id).zfill(3)  # Ensure filenames have leading zeros if needed\n",
        "\n",
        "    # Define image and mask paths\n",
        "    image_path = os.path.join(extract_folder, f\"{id_str}.png\")\n",
        "    mask_path = os.path.join(extract_folder, f\"{id_str}_Mask.png\")\n",
        "\n",
        "    try:\n",
        "        image = imread(image_path)\n",
        "        mask = imread(mask_path)\n",
        "\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Warning: File {image_path} or {mask_path} not found!\")\n",
        "\n",
        "# Confirm the number of loaded images and masks\n",
        "print(\"\\nTotal images loaded:\", len(images))\n",
        "print(\"Total masks loaded:\", len(masks))\n",
        "\n",
        "# First-order feature extraction function\n",
        "def get_first_order_stats(img):\n",
        "    entropy = stats.entropy(img, axis=None)\n",
        "    desc_stats = stats.describe(img, axis=None)\n",
        "    first_order_stats = np.array([\n",
        "        desc_stats.mean,\n",
        "        desc_stats.minmax[0],  # Min\n",
        "        desc_stats.minmax[1],  # Max\n",
        "        desc_stats.variance,\n",
        "        desc_stats.skewness,\n",
        "        desc_stats.kurtosis,\n",
        "        entropy\n",
        "    ])\n",
        "    return first_order_stats\n",
        "\n",
        "# Shape feature extraction function\n",
        "def get_shape_region_features(mask):\n",
        "    props = regionprops(mask)[0]\n",
        "    shape_region = np.array([\n",
        "        props.area,\n",
        "        props.area_bbox,\n",
        "        props.convex_area,\n",
        "        props.eccentricity,\n",
        "        props.extent,\n",
        "        props.major_axis_length,\n",
        "        props.minor_axis_length,\n",
        "        props.orientation,\n",
        "        props.perimeter,\n",
        "        props.solidity,\n",
        "        props.extent\n",
        "\n",
        "    ])\n",
        "    shape_region = np.insert(shape_region, [-1], props.moments_central.flatten())  # Moments\n",
        "    shape_region = np.insert(shape_region, [-1], props.moments_hu.flatten())  # Hu moments\n",
        "    return shape_region\n",
        "\n",
        "# Texture feature extraction function\n",
        "def get_texture_features(img):\n",
        "    glcm = graycomatrix(img, [1], [0, np.pi/4, np.pi/2, np.pi*3/4], levels=256, normed=True, symmetric=True)\n",
        "    texture_features = np.array([])\n",
        "    texture_features = np.insert(texture_features, [0], graycoprops(glcm, \"contrast\").flatten())\n",
        "    texture_features = np.insert(texture_features, [-1], graycoprops(glcm, \"dissimilarity\").flatten())\n",
        "    texture_features = np.insert(texture_features, [-1], graycoprops(glcm, \"homogeneity\").flatten())\n",
        "    texture_features = np.insert(texture_features, [-1], graycoprops(glcm, \"energy\").flatten())\n",
        "    texture_features = np.insert(texture_features, [-1], graycoprops(glcm, \"correlation\").flatten())\n",
        "    texture_features = np.insert(texture_features, [-1], graycoprops(glcm, \"ASM\").flatten())\n",
        "    return texture_features\n",
        "\n",
        "# Intensity-based feature function\n",
        "def get_intensity_features(img):\n",
        "    # Calculate gradient magnitude\n",
        "    gradient_x = np.gradient(img, axis=0)\n",
        "    gradient_y = np.gradient(img, axis=1)\n",
        "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
        "\n",
        "    # Get intensity features\n",
        "    intensity_features = np.array([\n",
        "        np.mean(gradient_magnitude),       # Mean gradient magnitude\n",
        "        np.std(gradient_magnitude),        # Standard deviation of gradient\n",
        "        np.percentile(img, 25),            # 25th percentile intensity\n",
        "        np.percentile(img, 75),            # 75th percentile intensity\n",
        "        np.max(img) - np.min(img)          # Dynamic range\n",
        "    ])\n",
        "    return intensity_features\n",
        "\n",
        "# Initialize an empty list to store features\n",
        "all_features = []\n",
        "some_features=[]\n",
        "\n",
        "# Loop through images and masks and extract features\n",
        "for img, mask in zip(images, masks):\n",
        "    first_order = get_first_order_stats(img)\n",
        "    shape_features = get_shape_region_features(mask)\n",
        "    texture_features = get_texture_features(img)\n",
        "    intensity_features = get_intensity_features(img)\n",
        "\n",
        "    # Combine all feature sets\n",
        "    combined_features = np.concatenate((first_order, shape_features, texture_features))\n",
        "    challenge2_combined_features = np.concatenate((first_order, intensity_features))\n",
        "\n",
        "    all_features.append(combined_features)\n",
        "    some_features.append(challenge2_combined_features)\n",
        "\n",
        "# Convert to a NumPy array for use in classification\n",
        "all_features = np.array(all_features)\n",
        "challenge2_features = np.array(some_features)\n",
        "\n",
        "# Print feature shape to verify extraction success\n",
        "print(\"Feature extraction completed!\")\n",
        "print(\"Feature array shape:\", all_features.shape)\n",
        "print(\"Challenge2 features array shape:\", challenge2_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP00gG7jIgwh",
        "outputId": "99d412f3-afbd-401d-c09a-0698968fc7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed!\n",
            "First 5 rows of the DataFrame:\n",
            "   file  class\n",
            "0    82      1\n",
            "1    27      1\n",
            "2    90      1\n",
            "3    76      1\n",
            "4    32      1\n",
            "\n",
            "Total images loaded: 453\n",
            "Total masks loaded: 453\n",
            "Feature extraction completed!\n",
            "Feature array shape: (453, 65)\n",
            "Challenge2 features array shape: (453, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5"
      ],
      "metadata": {
        "id": "GeHNd_thdS6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define feature matrix and target labels\n",
        "IMAGE_FEATURE_MATRIX = all_features  # The feature matrix from extracted features\n",
        "challenge2_matrix = challenge2_features\n",
        "CLASSES = class_labels  # The labels corresponding to each image\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "TRAIN_X, TEST_X, TRAIN_Y, TEST_Y = train_test_split(\n",
        "    IMAGE_FEATURE_MATRIX,  # Features\n",
        "    CLASSES,  # Target labels\n",
        "    test_size=0.2,  # 20% of data for testing\n",
        "    random_state=42  # Ensures reproducibility\n",
        ")\n",
        "\n",
        "TRAIN_X2, TEST_X2, TRAIN_Y2, TEST_Y2 = train_test_split(\n",
        "    challenge2_matrix,  # Features\n",
        "    CLASSES,  # Target labels\n",
        "    test_size=0.2,  # 20% of data for testing\n",
        "    random_state=42  # Ensures reproducibility\n",
        ")\n",
        "\n",
        "print(\"Training set size:\", len(TRAIN_X))\n",
        "print(\"Testing set size:\", len(TEST_X))\n",
        "print(\"Training set2 size:\", len(TRAIN_X2))\n",
        "print(\"Testing set2 size:\", len(TEST_X2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtZ6LNGE5nkX",
        "outputId": "bd665ee7-dacb-4d42-894a-8770d1cf5dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 362\n",
            "Testing set size: 91\n",
            "Training set2 size: 362\n",
            "Testing set2 size: 91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6,7,8"
      ],
      "metadata": {
        "id": "4KFXNOx-dmEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Learner\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "learner = DecisionTreeClassifier(random_state=42)  # You can specify more hyperparameters here if needed\n",
        "\n",
        "# Train the learner with the training data\n",
        "model = learner.fit(TRAIN_X, TRAIN_Y)  # TRAIN_X: features, TRAIN_Y: labels\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(TEST_X)  # TEST_X: test features\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(TEST_Y, predictions)  # TEST_Y: true labels\n",
        "print(\"Decision Tree Accuracy:\", accuracy)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(TEST_Y, predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN7QXtrnXNfI",
        "outputId": "b5198baf-afc3-4c77-dbb6-fd28ab3c8183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.7802197802197802\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.77      0.71      0.74        24\n",
            "           2       0.72      1.00      0.84        13\n",
            "           3       0.73      0.79      0.76        14\n",
            "           4       0.83      0.79      0.81        19\n",
            "           5       0.83      0.71      0.77        21\n",
            "\n",
            "    accuracy                           0.78        91\n",
            "   macro avg       0.78      0.80      0.78        91\n",
            "weighted avg       0.79      0.78      0.78        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 1 : Repeating the Prediction using three different algorithms (Random Forest, SVM, Decision Tree)"
      ],
      "metadata": {
        "id": "etbwhnGRhvds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "learner = RandomForestClassifier(random_state=42, n_estimators=1000)\n",
        "\n",
        "# Train the learner with the training data\n",
        "model = learner.fit(TRAIN_X, TRAIN_Y)  # TRAIN_X: features, TRAIN_Y: labels\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(TEST_X)  # TEST_X: test features\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(TEST_Y, predictions)  # TEST_Y: true labels\n",
        "print(\"Random Forest Accuracy:\", accuracy)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(TEST_Y, predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiSbn_-DX5OT",
        "outputId": "cb25e6ba-3f82-4792-d736-bfb0acc89822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9340659340659341\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        24\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.79      0.88        14\n",
            "           4       0.90      0.95      0.92        19\n",
            "           5       0.91      1.00      0.95        21\n",
            "\n",
            "    accuracy                           0.93        91\n",
            "   macro avg       0.95      0.93      0.93        91\n",
            "weighted avg       0.94      0.93      0.93        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "QI_93yMliPXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "learner = SVC(random_state=44, kernel='sigmoid', probability=True)\n",
        "\n",
        "model = learner.fit(TRAIN_X, TRAIN_Y)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(TEST_X)  # TEST_X: test features\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(TEST_Y, predictions)  # TEST_Y: true labels\n",
        "print(\"SVM Accuracy:\", accuracy)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(TEST_Y, predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYzIyJh8GF90",
        "outputId": "56d94b5f-038c-422b-8612-9bbb465f9938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.18681318681318682\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00        24\n",
            "           2       0.00      0.00      0.00        13\n",
            "           3       0.15      0.43      0.22        14\n",
            "           4       0.20      0.53      0.29        19\n",
            "           5       1.00      0.05      0.09        21\n",
            "\n",
            "    accuracy                           0.19        91\n",
            "   macro avg       0.27      0.20      0.12        91\n",
            "weighted avg       0.30      0.19      0.12        91\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After evaluating three different algorithms, Random Forest gives the highest accuracy with 0.93. Second being Decision tree with 0.78 accuracy and the algorithm with the least accuracy is SVM with 0.18. Hence Random Forest is the best performing algorithm"
      ],
      "metadata": {
        "id": "3ynXkHaxihsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 2"
      ],
      "metadata": {
        "id": "EPfv4JVHkJew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "learner = RandomForestClassifier(random_state=4, n_estimators=1000)\n",
        "\n",
        "model = learner.fit(TRAIN_X2, TRAIN_Y2)  # TRAIN_X2: features, TRAIN_Y2: labels\n",
        "\n",
        "predictions = model.predict(TEST_X2)  # TEST_X2: test features\n",
        "\n",
        "# Evaluate the predictions\n",
        "accuracy = accuracy_score(TEST_Y2, predictions)  # TEST_Y2: true labels\n",
        "print(\"Random Forest Accuracy:\", accuracy)\n",
        "\n",
        "# Classification report\n",
        "report = classification_report(TEST_Y2, predictions)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77yOj3EJN7Kd",
        "outputId": "ba3328b6-690e-4cec-95bd-c75bf0195267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.945054945054945\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.96      0.96        24\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.93      0.96        14\n",
            "           4       0.86      0.95      0.90        19\n",
            "           5       0.95      0.90      0.93        21\n",
            "\n",
            "    accuracy                           0.95        91\n",
            "   macro avg       0.95      0.95      0.95        91\n",
            "weighted avg       0.95      0.95      0.95        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I repeated the prediction using a different feature set (Intensity Features) on the best performing algorithm (Random Forest). It has improved the prediction from 0.93 to 0.94 compared to using all features."
      ],
      "metadata": {
        "id": "UHAk_ri-35kR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 3: Cross Validation"
      ],
      "metadata": {
        "id": "NIIYjoA31A36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "scoring = ['accuracy']\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    learner, TRAIN_X, TRAIN_Y,\n",
        "    cv=5,  # Number of cross-validation folds\n",
        "    scoring= scoring,\n",
        "    return_train_score=True  # Get training scores as well\n",
        ")\n",
        "\n",
        "# Step 4: Display cross-validation results\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(\"Train Accuracy (mean):\", cv_results['train_accuracy'].mean())\n",
        "print(\"Test Accuracy (mean):\", cv_results['test_accuracy'].mean())\n",
        "print(\"Cross-Validation Details:\")\n",
        "print(cv_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfcMo40vx_RU",
        "outputId": "31d6e9e3-59ae-4c95-c51d-eca84947a4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Results:\n",
            "Train Accuracy (mean): 1.0\n",
            "Test Accuracy (mean): 0.903538812785388\n",
            "Cross-Validation Details:\n",
            "{'fit_time': array([3.54212499, 2.62730765, 2.68502879, 2.66187644, 3.4333477 ]), 'score_time': array([0.07509661, 0.06975007, 0.0680151 , 0.07541633, 0.11781335]), 'test_accuracy': array([0.84931507, 0.87671233, 0.93055556, 0.93055556, 0.93055556]), 'train_accuracy': array([1., 1., 1., 1., 1.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenge 4: Grid search cross validation"
      ],
      "metadata": {
        "id": "LXjB53GM1nIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Assuming you already have X_train, X_test, y_train, y_test\n",
        "\n",
        "# Define cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define parameter grids for different classifiers\n",
        "\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "# Create classifiers\n",
        "classifiers = {\n",
        "\n",
        "    'Random Forest': (RandomForestClassifier(), param_grid_rf),\n",
        "\n",
        "}\n",
        "\n",
        "# Dictionary to store the best models\n",
        "best_models = {}\n",
        "\n",
        "# Perform grid search for each classifier\n",
        "for name, (classifier, param_grid) in classifiers.items():\n",
        "    print(f\"\\nPerforming grid search for {name}...\")\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=classifier,\n",
        "        param_grid=param_grid,\n",
        "        cv=cv,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Fit grid search\n",
        "    grid_search.fit(TRAIN_X, TRAIN_Y)\n",
        "\n",
        "    # Get best model\n",
        "    best_models[name] = grid_search.best_estimator_\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = grid_search.predict(TEST_X)\n",
        "    test_accuracy = accuracy_score(TEST_Y, y_pred)\n",
        "    print(f\"Test accuracy with best {name}: {test_accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(TEST_Y, y_pred))\n",
        "\n",
        "# Find the overall best model\n",
        "best_model_name = max(best_models, key=lambda name: accuracy_score(TEST_Y, best_models[name].predict(TEST_X)))\n",
        "best_model = best_models[best_model_name]\n",
        "\n",
        "print(f\"\\n\\nThe best overall model is {best_model_name} with test accuracy: \"\n",
        "      f\"{accuracy_score(TEST_Y, best_model.predict(TEST_X)):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlIx7MUzEyXH",
        "outputId": "6721c5a6-3ec2-43be-e1b5-ef5821a49580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing grid search for Random Forest...\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best parameters for Random Forest: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best cross-validation score: 0.9199\n",
            "Test accuracy with best Random Forest: 0.9341\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.92      0.92      0.92        24\n",
            "           2       1.00      1.00      1.00        13\n",
            "           3       1.00      0.79      0.88        14\n",
            "           4       0.90      0.95      0.92        19\n",
            "           5       0.91      1.00      0.95        21\n",
            "\n",
            "    accuracy                           0.93        91\n",
            "   macro avg       0.95      0.93      0.93        91\n",
            "weighted avg       0.94      0.93      0.93        91\n",
            "\n",
            "\n",
            "\n",
            "The best overall model is Random Forest with test accuracy: 0.9341\n"
          ]
        }
      ]
    }
  ]
}